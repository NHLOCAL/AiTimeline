- year: 2022
  events:
  - date: February
    info:
    - text: <b>Midjourney v1</b>
      type: image
  - date: March
    info:
    - text: OpenAI releases <b>text-davinci-002</b> and <b>code-davinci-002</b> with an API approach.
      type: language
  - date: April
    info:
    - text: <b>Midjourney v2</b>
      type: image
    - text: <b>DALL-E 2</b> is announced for gradual release.
      type: image
      special: true
  - date: July
    info:
    - text: <b>Midjourney v3</b> is launched.
      type: image
  - date: August
    info:
    - text: <b>Stable Diffusion 1.4</b> is released.
      type: image
  - date: October
    info:
    - text: <b>Stable Diffusion 1.5</b> becomes available.
      type: image
  - date: November
    info:
    - text: <b>ChatGPT</b>, a chatbot by OpenAI using GPT-3.5, is released to the public and quickly becomes a viral sensation.
      type: chatbot
      special: true
    - text: <b>Midjourney v4</b> is released.
      type: image
    - text: <b>Stable Diffusion 2.0</b> is launched.
      type: image
  - date: December
    info:
    - text: <b>Stable Diffusion 2.1</b> is released.
      type: image
- year: 2023
  events:
  - date: February
    info:
    - text: Meta releases the <b>LLaMA</b> language model as open-source for research purposes. The model is later leaked.
      type: language
      special: true
    - text: Microsoft gradually releases <b>Bing AI</b>, an AI chat based on an upgraded GPT model integrating internet search.
      type: chatbot
  - date: March
    info:
    - text: <b>Midjourney v5</b> is launched.
      type: image
    - text: OpenAI's <b>GPT-4</b> model is partially released, featuring multimodal image analysis and improved multi-language support.
      type: language
    - text: Google releases the AI chat <b>Bard</b> in a limited capacity, based on the LaMDA language model.
      type: chatbot
  - date: April
    info:
    - text: Adobe releases the <b>Firefly</b> image creation model as a beta version to a waiting list. The model allowed a variety of capabilities including text formatting.
      type: image
  - date: May
    info:
    - text: <b>Midjourney v5.1</b> is released.
      type: image
    - text: Google announces an upgrade to Bard, moving it to the upgraded <b>PaLM 2</b> language model. It will support 180 countries and many languages.
      type: chatbot
  - date: June
    info:
    - text: <b>Midjourney v5.2</b> is launched.
      type: image
  - date: July
    info:
    - text: <b>Stable Diffusion XL 1.0</b> is released.
      type: image
    - text: Anthropic announces a new version of their large language model - <b>Claude 2</b>.
      type: language
    - text: Meta releases the <b>LLaMA 2</b> open source language model to the general public in a variety of sizes.
      type: language
  - date: October
    info:
    - text: <b>DALL-E 3</b> is released.
      type: image
    - text: Adobe releases <b>Firefly 2</b>.
      type: image
  - date: November
    info:
    - text: <b>Stable Diffusion XL Turbo</b> is released - A fast model that allows the creation of an image in one step in real time.
      type: image
  - date: December
    info:
    - text: <b>Midjourney v6</b> is launched.
      type: image
    - text: Google upgrades Bard in limited areas, moving it to be based on the upgraded <b>Gemini Pro</b> language model.
      type: chatbot
    - text: X Corporation launches <b>Grok AI</b> chatbot for paid subscribers in English language.
      type: chatbot
- year: 2024
  events:
  - date: February
    info:
    - text: Stability AI announces <b>Stable Diffusion 3</b> (gradually released to waiting list).
      type: image
    - text: Google upgrades the artificial intelligence chat in Bard, basing it on the new <b>Gemini Pro</b> model, in all available languages. Google replaces "Bard" with "Gemini".
      type: chatbot
    - text: Google announces the <b>Gemini Pro 1.5</b> multimodal language model capable of parsing up to a million tokens, as well as parsing video and images. The model is gradually released to developers on a waiting list.
      type: multimodal
      special: true
    - text: OpenAI announces the <b>Sora</b> model that produces videos up to a minute long. The model is not released to the public at this time.
      type: video
      special: true
  - date: March
    info:
    - text: X Corporation announces the upcoming release of the <b>Grok 1.5</b> open source model.
      type: language
    - text: Anthropic announces <b>Claude 3</b>, a new version of their large language model. The version is deployed in 3 different sizes, with the largest model performing better than GPT-4.
      type: language
    - text: Suno AI, which develops a model for creating music, releases <b>Suno v3</b> to the general public.
      type: music
  - date: April
    info:
    - text: Stability AI releases a new update to the music creation model - <b>Stable Audio 2.0</b>.
      type: music
    - text: X Corporation releases an upgrade to its language model, <b>Grok-1.5V</b>, which integrates high-level image recognition. In the test presented by the company, the model is the best in identifying and analyzing images compared to other models.
      type: multimodal
    - text: The Mistral company releases its new model <b>Mixtral 8x22B</b> as open source. This is the most powerful model among the open source models and it contains 141 billion parameters but uses a method that allows more economical use.
      type: language
    - text: Meta releases the <b>LLaMA 3</b> model as open source in sizes 8B and 70B parameters. The large model shows better performance than Claude 3 Sonnet and Gemini Pro 1.5 in several measures. Meta is expected to later release larger models with 400 billion parameters and more.
      type: language
    - text: Microsoft releases the <b>Phi-3-mini</b> model in open source. The model comes in a reduced version of 3.8B parameters, which allows it to run on mobile devices as well, and it presents capabilities similar to GPT-3.5.
      type: language
      special: true
    - text: Adobe announces its new image creation model <b>Firefly 3</b>.
      type: image
    - text: The startup <b>Reka AI</b> presents a series of multimodal language models in 3 sizes. The models are capable of processing video, audio and images. The large model featured similar capabilities to GPT-4.
      type: multimodal
    - text: Apple releases as full open source a series of small language models under the name <b>OpenELM</b>. The models are available in four weights between 270 million and 3 billion parameters.
      type: language
  - date: May
    info:
    - text: OpenAI announces the <b>GPT-4o model</b> that presents full multimodal capabilities, including receiving and creating text, images, and audio. The model presents an impressive ability to speak with a high response speed and in natural language. The model is 2 times more efficient than the GPT-4 Turbo model, and has better capabilities for languages other than English.
      type: multimodal
      special: true
    - text: Google announces increasing the token limit to 2 million for Gemini 1.5 to waiting list.
      type: language
    - text: Google releases a smaller and faster <b>Gemini Flash 1.5 model</b>.
      type: language
    - text: Google reveals the latest image creation model <b>Imagen 3</b>.
      type: image
    - text: Google reveals the music creation model <b>Music AI</b>.
      type: music
    - text: Google reveals the video creation model <b>Veo</b>.
      type: video
    - text: Google announces the <b>Astra model</b> with multimodal capabilities for realtime audio and video reception.
      type: multimodal
    - text: Microsoft announces <b>Copilot+</b> for dedicated computers, which will allow a full search of the user's history through screenshots of the user's activity.
      type: agent
    - text: 'Microsoft releases as open source the SLMs: <b>Phi-3 Small</b>, <b>Phi-3 Medium</b>.'
      type: language
    - text: Microsoft releases as open source <b>Phi-3 Vision</b> which includes image recognition capability.
      type: multimodal
    - text: Meta introduces <b>Chameleon</b>, a new multimodal model that seamlessly renders text and images.
      type: multimodal
    - text: Mistral AI releases a new open source version of its language model <b>Mistral-7B-Instruct-v0.3</b>.
      type: language
    - text: Google announces <b>AI Overviews</b> intended to give a summary of the relevant information in Google search.
      type: chatbot
      special: true
    - text: Suno AI releases an updated music creation model <b>Suno v3.5</b>.
      type: music
    - text: Mistral AI releases a new language model designed for coding <b>Codestral</b> in size 22B.
      type: language
  - date: June
    info:
    - text: Stability AI releases its updated image creation model <b>Stable Diffusion 3</b> in a medium version in size 2B parameters.
      type: image
    - text: Apple announces <b>Apple Intelligence</b>, an AI system that will be integrated into the company's devices and will combine AI models of different sizes for different tasks.
      type: general
    - text: DeepSeekAI publishes the <b>DeepSeekCoderV2</b> open source language model which presents similar coding capabilities to models such as GPT-4, Claude 3 Opus and more.
      type: language
    - text: <b>Runway</b> introduces <b>Gen3 Alpha</b>, a new AI model for video generation.
      type: video
    - text: Anthropic releases the <b>Claude Sonnet 3.5</b> model, which presents better capabilities than other models with low resource usage.
      type: language
      special: true
    - text: Microsoft releases in open source a series of image recognition models called <b>Florence 2</b>.
      type: image
    - text: Google announces <b>Gemma 2</b> open source language models with 9B and 27B parameter sizes.
      type: language
    - text: Google opens the context window capabilities to developers for up to 2 million tokens.
      type: language
  - date: July
    info:
    - text: OpenAI has released a miniaturized model called <b>GPT-4o mini</b> that presents high capabilities at a low cost
      type: language
    - text: Meta releases as open source the <b>llama 3.1 model</b> in sizes 8B, 70B and 405B. The large model features the same capabilities as the best closed source models
      type: language
      special: true
    - text: 'mistral ai releases three new models: <b>Codestral Mamba</b>, <b>Mistral NeMo</b> and <b>Mathstral</b> designed for mathematics'
      type: language
    - text: Google DeepMind has unveiled two new AI systems that won silver medals at this year's International Mathematical Olympiad (IMO),  <b>AlphaProof</b> and <b>AlphaGeometry 2</b>.
      type: research
      special: true
    - text: OpenAI launched <b>SearchGPT</b>, an integrated web search
      type: chatbot
    - text: Startup Udio has released <b>Udio v1.5</b>, an updated version of its music creation model
      type: music
    - text: Mistral AI has released a large language model <b>Mistral Large 2</b> in size 123B, which presents capabilities close to the closed SOTA models.
      type: language
      special: true
    - text: <b>Midjourney v6.1</b> is released
      type: image
    - text: Google releases the <b>Gemma 2 2B</b> model as open source. The model demonstrates better capabilities than much larger models.
      type: language
  - date: August
    info:
    - text: '"Black Forest Labs" releases weights for an image creation model named <b>Flux</b>, which shows better performance than similar closedsource models.'
      type: image
    - text: OpenAI released a new version of its model, <b>GPT-4o 0806</b>, achieving 100% success in generating valid JSON output.
      type: language
    - text: Google's image generation model, <b>Imagen 3</b>, has been released.
      type: image
    - text: xAI Corporation has launched the models <b>Grok 2</b> and <b>Grok 2 mini</b>, which demonstrate performance on par with leading SOTA models in the market.
      type: language
    - text: Microsoft has introduced its small language models, <b>Phi 3.5</b>, in three versions, each showcasing impressive performance relative to their size.
      type: language
    - text: 'Google has introduced three new experimental AI models: <b>Gemini 1.5 Flash8B</b>, <b>Gemini 1.5 Pro</b> Enhanced, and <b>Gemini 1.5 Flash</b> Updated.'
      type: language
    - text: <b>Ideogram 2.0</b> has been released, offering image generation capabilities that surpass those of other leading models.
      type: image
    - text: Luma has unveiled the <b>Dream Machine 1.5</b> model for video creation.
      type: video
  - date: September
    info:
    - text: The French AI company Mistral has introduced <b>Pixtral12B</b>, its first multimodal model capable of processing both images and text.
      type: multimodal
    - text: 'OPENAI has released two nextgeneration AI models to its subscribers: <b>o1 preview</b> and <b>o1 mini</b>. These models show a significant improvement in performance, particularly in tasks requiring reasoning, including coding, mathematics, GPQA, and more.'
      type: language
      special: true
    - text: Chinese company Alibaba releases the <b>Qwen 2.5</b> model in various sizes, ranging from 0.5B to 72B. The models demonstrate capabilities comparable to much larger models.
      type: language
    - text: The video generation model <b>KLING 1.5</b> has been released.
      type: video
    - text: <b>OpenAI</b> launches the <b>advanced voice mode</b> of GPT4o for all subscribers.
      type: multimodal
    - text: <b>Meta</b> releases <b>Llama 3.2</b> in sizes 1B, 3B, 11B and 90B, featuring image recognition capabilities for the first time.
      type: language
    - text: <b>Google</b> has rolled out new model updates ready for deployment, <b>Gemini Pro 1.5 002</b> and <b>Gemini Flash 1.5 002</b>, showcasing significantly improved longcontext processing.
      type: language
    - text: <b>Kyutai</b> releases two opensource versions of its voicetovoice model, <b>Moshi</b>.
      type: multimodal
    - text: Google releases an update to its AI tool <b>NotebookLM</b> that enables users to create podcasts based on their own content.
      type: general
    - text: Mistral AI launches a 22B model named <b>Mistral Small</b>.
      type: language
  - date: October
    info:
    - text: <b>Flux 1.1 Pro</b> is released, showcasing advanced capabilities for image creation.
      type: image
    - text: Meta unveils <b>Movie Gen</b>, a new AI model that generates videos, images, and audio from text input.
      type: video
    - text: Pika introduces <b>Video Model 1.5</b> along with "Pika Effects."
      type: video
    - text: Adobe announces its video creation model, <b>Firefly Video</b>.
      type: video
    - text: Startup Rhymes AI releases <b>Aria</b>, an opensource, multimodal model exhibiting capabilities similar to comparably sized proprietary models.
      type: multimodal
    - text: Meta releases an opensource speechtospeech language model named <b>Meta Spirit LM</b>.
      type: language
    - text: Mistral AI introduces <b>Ministral</b>, a new model available in 3B and 8B parameter sizes.
      type: language
    - text: <b>Janus AI</b>, a multimodal language model capable of recognizing and generating both text and images, is released as open source by DeepSeekAI.
      type: multimodal
    - text: Google DeepMind and MIT unveil <b>Fluid</b>, a texttoimage generation model with industryleading performance at a scale of 10.5B parameters.
      type: image
    - text: <b>Stable Diffusion 3.5</b> is released in three sizes as open source.
      type: image
    - text: Anthropic launches <b>Claude 3.5 Sonnet New</b>, demonstrating significant advancements in specific areas over its previous version, and announces <b>Claude 3.5 Haiku</b>.
      type: language
    - text: Anthropic announces an experimental feature for computer use with a public beta API.
      type: agent
    - text: The texttoimage model <b>Recraft v3</b> has been released to the public, ranking first in benchmarks compared to similar models.
      type: image
    - text: OpenAI has launched <b>Search GPT</b>, allowing users to perform web searches directly within the platform.
      type: chatbot
  - date: November
    info:
    - text: Alibaba released its new model, <b>QwQ 32B Preview</b>, which integrates reasoning capabilities before responding. The model competes with, and sometimes surpasses, OpenAI's o1-preview model.
      type: language
    - text: Alibaba opensourced the model <b>Qwen2.5 Coder 32B</b>, which offers comparable capabilities to leading proprietary language models in the coding domain.
      type: language
    - text: DeepSeek unveiled its new AI model, <b>DeepSeek-R1-Lite-Preview</b>, which incorporates reasoning capabilities and delivers impressive performance on the AIME and MATH benchmarks, matching the level of OpenAI's o1-preview.
      type: language
    - text: <b>Suno</b> upgraded its AIpowered music generator to <b>v4</b>, introducing new features and performance improvements.
      type: music
    - text: Mistral AI launched the <b>Pixtral Large</b> model, a multimodal language model excelling in image recognition and advanced performance metrics.
      type: multimodal
    - text: Mistral AI launched an update to Mistral Large, 2411.
      type: language
    - text: Google introduced two experimental models, <b>gemini-exp-1114</b> and <b>gemini-exp-1121</b>, currently leading the arena chatbot with enhanced performance.
      type: language
    - text: Anthropic launches <b>Claude 3.5 Haiku</b> and Visual PDF Analysis in Claude.
      type: language
  - date: December
    info:
    - text: Amazon introduced a new series of models called <b>NOVA</b>, designed for text, image, and video processing.
      type: multimodal
    - text: OpenAI released <b>SORA</b>, a video generation model.
      type: video
      special: true
    - text: OpenAI released the full version of <b>O1</b> and <b>O1 Pro</b> for advanced subscribers.
      type: language
      special: true
    - text: OpenAI launched a live video mode for <b>GPT4o</b>.
      type: multimodal
      special: true
    - text: Google unveiled the experimental model <b>Gemini-Exp-1206</b>, which ranked first in the chatbot leaderboard.
      type: language
    - text: Google launched <b>Gemini 2.0 Flash</b> in beta. This model leads benchmarks and outperforms the previous version, <b>Gemini Pro 1.5</b>.
      type: language
      special: true
    - text: Google introduced live speech and video mode for Gemini 2.0 Flash.
      type: multimodal
      special: true
    - text: Google announced built-in image generation capabilities within Gemini 2.0 Flash.
      type: image
      special: true
    - text: Google revealed <b>Gemini-2.0-Flash-Thinking</b>, a thinking model based on <b>Gemini 2.0 Flash</b>, which secured second place in the chatbot leaderboard.
      type: language
      special: true
    - text: Google introduced <b>Veo 2</b>, a beta version video generation model capable of producing 4K videos up to two minutes long. The model outperformed <b>SORA</b> in human evaluations.
      type: video
      special: true
    - text: Google updated <b>Imagen 3</b>, offering enhanced image quality and realism.
      type: image
      special: true
    - text: xAI integrated <b>Aurora</b>, a new model for generating high-quality and realistic images.
      type: image
    - text: Microsoft open-sourced the <b>Phi4</b> model, sized at 14B, showcasing impressive capabilities for its size.
      type: language
    - text: Meta released <b>Llama 3.3 70B</b>, a model offering performance comparable to <b>Llama 3.1 405B</b>.
      type: language
    - text: Google launched a multi-modal open-source model called <b>PaliGemma 2</b>, integrated with existing <b>Gemma</b> models.
      type: multimodal
    - text: Pika Labs released <b>2.0</b>, the latest version of its AI-powered video generator.
      type: video
    - text: Meta introduced <b>Apollo</b>, a video generation model available in three different sizes.
      type: video
    - text: Deepseek open-sourced <b>Deepseek V3</b>, a model with 671B parameters that surpasses closed-source SOTA models across several benchmarks.
      type: language
      special: true
    - text: Alibaba unveiled <b>QVQ-72B-Preview</b>, a cutting-edge thinking model capable of analyzing images, featuring SOTA-level performance.
      type: language
      special: true
    - text: OpenAI announced <b>O3</b>, a groundbreaking AI model achieving 87.5% in the <b>ARC-AGI</b> benchmark, 25.2% in the <b>Frontier Math Benchmark</b> (compared to under 2% in previous models), and 87.7% in Ph.D.-level science questions.
      type: language
      special: true
    - text: OpenAI announced <b>O3 Mini</b>, a cost-effective version expected in January 2025, with performance similar to <b>O1</b>, alongside improved speed and efficiency.
      type: language
      special: true
    - text: The video generation model <b>Kling 1.6</b> was released, offering significant performance enhancements.
      type: video
- year: 2025
  events:
  - date: January
    info:
    - text: OpenAI released <b>Operator</b> for Pro subscribers – an experimental AI agent capable of browsing websites and performing actions.
      type: agent
      special: true
    - text: Google introduced <b>Gemini Flash Thinking 0121</b>, an enhanced reasoning model that secured the top spot in the Arena Chatbots rankings.
      type: language
    - text: DeepSeek open-sourced the reasoning models <b>R1</b> and <b>R1-Zero</b>, which demonstrated capabilities similar to <b>o1</b> across various domains at a fraction of the cost. Additionally, smaller distilled models were released, achieving high performance relative to their size.
      type: language
      special: true
    - text: Google published a research paper on a new language model architecture called <b>Titans</b>, designed to enable models to retain both short- and long-term memory. This architecture significantly improves processing for extended context windows.
      type: research
      special: true
    - text: DeepSeek open-sourced a fully multimodal model, <b>Janus Pro 7B</b>, which supports both text and image generation.
      type: multimodal
    - text: Alibaba unveiled <b>Qwen2.5-Max</b>, a large language model that surpasses several leading models, including <b>DeepSeek-V3</b>, <b>GPT-4o</b>, and <b>Claude 3.5</b>.
      type: language
    - text: Alibaba open-sourced the <b>Qwen2.5-1M</b> series, capable of processing up to one million tokens.
      type: language
    - text: Alibaba open-sourced the <b>Qwen2.5-VL</b> vision model series in three different sizes.
      type: multimodal
    - text: OpenAI made the <b>o3 mini</b> reasoning model available to all users, including the free tier, featuring three reasoning levels. The model matches or comes close to o1 in several benchmarks, significantly surpasses it in coding, and remains significantly faster and more cost-efficient.
      type: language
      special: true
  - date: February 2025
    info:
    - text: xAI launches <b>Grok 3</b>, <b>Grok 3 Reasoning</b> and <b>Grok 3 mini</b>, next-generation AI models trained with 10 times the computing power of Grok 2, significantly improving SOTA performance. They include "Think" and "Big Brain" modes for advanced reasoning.
      type: language
      special: true
    - text: xAI launches <b>DeepSearch</b> for autonomous web searches with Grok 3.
      type: agent
      special: true
    - text: Anthropic introduces <b>Claude 3.7</b> and <b>Claude 3.7 Thinking</b>, a new model with enhanced coding performance, support for "Extended Thinking" mode, and the ability to analyze reasoning processes.
      type: language
      special: true
    - text: OpenAI unveils <b>Deep Research</b>, a tool for autonomous research, enabling real-time web searches and comprehensive report generation.
      type: agent
      special: true
    - text: Google releases <b>Gemini 2.0 Flash</b>, <b>Gemini 2.0 Flash-Lite Preview</b>, and <b>Gemini 2.0 Pro Experimental</b>.
      type: language
    - text: Alibaba launches <b>QwQ-Max</b> – a reasoning model based on Qwen2.5-Max, offering improved analytical and logical capabilities.
      type: language
    - text: Microsoft presents <b>Phi4-mini</b> and <b>Phi4 Multimodal</b>, lightweight models (3.8B and 5.6B) with enhanced performance, including support for multimodal inputs.
      type: language
    - text: OpenAI releases <b>GPT-4.5</b>, featuring advanced pattern recognition and significantly reduced hallucinations, improving accuracy and reliability.
      type: language
      special: true
  - date: March 2025
    info:
    - text: Google introduced <b>Gemini 2.5 Pro</b>, an experimental "Thinking model" with advanced reasoning and planning capabilities, a 1 million token context window, achieving top rankings across several key benchmarks.
      type: language
      special: true
    - text: Google launched the Gemma 3 series, featuring open-source multimodal models in various parameter sizes, a 128K context window, multi-language support, and integrated image and video understanding capabilities.
      type: multimodal
    - text: OpenAI integrated <b>GPT-4o Image Generation</b>, enabling high-fidelity text-to-image creation, text rendering within images, and more.
      type: image
      special: true
    - text: Google expanded experimental image generation and editing within <b>Gemini 2.0 Flash Experimental</b>, enabling image generation and editing, including enhanced text creation capabilities.
      type: image
      special: true
    - text: Alibaba released <b>QwQ-32B</b>, an open-source 32B parameter reasoning model with exceptional math and coding performance, rivaling much larger models.
      type: language
    - text: Alibaba released the <b>Qwen2.5-VL 32B</b>, open-source vision-language model with robust capabilities in visual analysis, text-in-image understanding, and visual agent tasks.
      type: multimodal
    - text: DeepSeek updated its open-source MoE model with <b>DeepSeek-V3-0324</b>, featuring enhanced reasoning, coding, and math capabilities, positioning it as a top-tier base model.
      type: language
    - text: Sesame AI unveiled its <b>Conversational Speech Model (CSM)</b>, enabling remarkably human-like, real-time voice interaction, incorporating emotional nuances, natural pauses, laughter, and contextual memory.
      type: multimodal
      special: true
