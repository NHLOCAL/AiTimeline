# Year: 2022

## February
- **Midjourney v1**

## March
- OpenAI releases **text-davinci-002** and **code-davinci-002** with an API approach.

## April
- **Midjourney v2**
- **DALL-E 2** is announced for gradual release. (*special*)

## July
- **Midjourney v3** is launched.

## August
- **Stable Diffusion 1.4** is released.

## October
- **Stable Diffusion 1.5** becomes available. (*special*)

## November
- **ChatGPT**, a chatbot by OpenAI using GPT-3.5, is released to the public and quickly becomes a viral sensation. (*special*)
- **Midjourney v4** is released.
- **Stable Diffusion 2.0** is launched.

## December
- **Stable Diffusion 2.1** is released.


# Year: 2023

## February
- Meta releases the **LLaMA** language model as open-source for research purposes. The model is later leaked. (*special*)
- Microsoft gradually releases **Bing AI**, an AI chat based on an upgraded GPT model integrating internet search.

## March
- **Midjourney v5** is launched.
- OpenAI's **GPT-4** model is partially released, featuring multimodal image analysis and improved multi-language support. (*special*)
- Google releases the AI chat **Bard** in a limited capacity, based on the LaMDA language model.

## April
- Adobe releases the **Firefly** image creation model as a beta version to a waiting list. The model allowed a variety of capabilities including text formatting.

## May
- **Midjourney v5.1** is released.
- Google announces an upgrade to Bard, moving it to the upgraded **PaLM 2** language model. It will support 180 countries and many languages.

## June
- **Midjourney v5.2** is launched.

## July
- **Stable Diffusion XL 1.0** is released.
- Anthropic announces a new version of their large language model - **Claude 2**.
- Meta releases the **LLaMA 2** open source language model to the general public in a variety of sizes.

## October
- **DALL-E 3** is released.
- Adobe releases **Firefly 2**.

## November
- **Stable Diffusion XL Turbo** is released - A fast model that allows the creation of an image in one step in real-time.

## December
- **Midjourney v6** is launched.
- Google upgrades Bard in limited areas, moving it to be based on the upgraded **Gemini Pro** language model.
- X Corporation launches **Grok AI** chatbot for paid subscribers in English language.


# Year: 2024

## February
- Stability AI announces **Stable Diffusion 3** (gradually released to waiting list).
- Google upgrades the artificial intelligence chat in Bard, basing it on the new **Gemini Pro** model, in all available languages. Google replaces "Bard" with "Gemini".
- Google announces the **Gemini Pro 1.5** multimodal language model capable of parsing up to a million tokens, as well as parsing video and images. The model is gradually released to developers on a waiting list. (*special*)
- OpenAI announces the **Sora** model that produces videos up to a minute long. The model is not released to the public at this time. (*special*)

## March
- X Corporation announces the upcoming release of the **Grok 1.5** open source model.
- Anthropic announces **Claude 3**, a new version of their large language model. The version is deployed in 3 different sizes, with the largest model performing better than GPT-4.
- Suno AI, which develops a model for creating music, releases **Suno v3** to the general public.

## April
- Stability AI releases a new update to the music creation model - **Stable Audio 2.0**.
- X Corporation releases an upgrade to its language model, **Grok-1.5V**, which integrates high-level image recognition. In the test presented by the company, the model is the best in identifying and analyzing images compared to other models.
- The Mistral company releases its new model **Mixtral 8x22B** as open source. This is the most powerful model among the open source models and it contains 141 billion parameters but uses a method that allows more economical use.
- Meta releases the **LLaMA 3** model as open source in sizes 8B and 70B parameters. The large model shows better performance than Claude 3 Sonnet and Gemini Pro 1.5 in several measures. Meta is expected to later release larger models with 400 billion parameters and more.
- Microsoft releases the **Phi-3-mini** model in open source. The model comes in a reduced version of 3.8B parameters, which allows it to run on mobile devices as well, and it presents capabilities similar to GPT-3.5. (*special*)
- Adobe announces its new image creation model **Firefly 3**.
- The startup **Reka AI** presents a series of multimodal language models in 3 sizes. The models are capable of processing video, audio and images. The large model featured similar capabilities to GPT-4.
- Apple releases as full open source a series of small language models under the name **OpenELM**. The models are available in four weights between 270 million and 3 billion parameters.

## May
- OpenAI announces the **GPT-4o model** that presents full multimodal capabilities, including receiving and creating text, images, and audio. The model presents an impressive ability to speak with a high response speed and in natural language. The model is 2 times more efficient than the GPT-4 Turbo model, and has better capabilities for languages other than English. (*special*)
- Google announces a large number of AI features in its products. The main ones: increasing the token limit to 2 million for Gemini 1.5 to waiting list, releasing a smaller and faster **Gemini Flash 1.5 model**. Revealing the latest image creation model **Imagen 3**, music creation model **Music AI** and video creation model **Veo**. And the announcement of the **Astra model** with multimodal capabilities for realtime audio and video reception.
- Microsoft announces **Copilot+** for dedicated computers, which will allow a full search of the user's history through screenshots of the user's activity. The company also released as open source the SLMs that display impressive capabilities in a minimal size: **Phi-3 Small**, **Phi-3 Medium**, and **Phi-3 Vision** which includes image recognition capability.
- Meta introduces **Chameleon**, a new multimodal model that seamlessly renders text and images.
- Mistral AI releases a new open source version of its language model **Mistral-7B-Instruct-v0.3**.
- Google announces **AI Overviews** intended to give a summary of the relevant information in Google search. (*special*)
- Suno AI releases an updated music creation model **Suno v3.5**.
- Mistral AI releases a new language model designed for coding **Codestral** in size 22B.

## June
- Stability AI releases its updated image creation model **Stable Diffusion 3** in a medium version in size 2B parameters.
- Apple announces **Apple Intelligence**, an AI system that will be integrated into the company's devices and will combine AI models of different sizes for different tasks.
- DeepSeekAI publishes the **DeepSeekCoderV2** open source language model which presents similar coding capabilities to models such as GPT-4, Claude 3 Opus and more.
- **Runway** introduces **Gen3 Alpha**, a new AI model for video generation.
- Anthropic releases the **Claude Sonnet 3.5** model, which presents better capabilities than other models with low resource usage. (*special*)
- Microsoft releases in open source a series of image recognition models called **Florence 2**.
- Google announces **Gemma 2** open source language models with 9B and 27B parameter sizes. Also, the company opens the context window capabilities to developers for up to 2 million tokens.

## July
- OpenAI has released a miniaturized model called **GPT-4o mini** that presents high capabilities at a low cost
- Meta releases as open source the **llama 3.1 model** in sizes 8B, 70B and 405B. The large model features the same capabilities as the best closed source models (*special*)
- mistral ai releases three new models: **Codestral Mamba**, **Mistral NeMo** and **Mathstral** designed for mathematics
- Google DeepMind has unveiled two new AI systems that won silver medals at this year's International Mathematical Olympiad (IMO),  **AlphaProof** and **AlphaGeometry 2**. (*special*)
- OpenAI launched **SearchGPT**, an integrated web search
- Startup Udio has released **Udio v1.5**, an updated version of its music creation model
- Mistral AI has released a large language model **Mistral Large 2** in size 123B, which presents capabilities close to the closed SOTA models. (*special*)
- **Midjourney v6.1** is released
- Google releases the **Gemma 2 2B** model as open source. The model demonstrates better capabilities than much larger models.

## August
- "Black Forest Labs" releases weights for an image creation model named **Flux**, which shows better performance than similar closedsource models.
- OpenAI released a new version of its model, **GPT-4o 0806**, achieving 100% success in generating valid JSON output.
- Google's image generation model, **Imagen 3**, has been released.
- xAI Corporation has launched the models **Grok 2** and **Grok 2 mini**, which demonstrate performance on par with leading SOTA models in the market.
- Microsoft has introduced its small language models, **Phi 3.5**, in three versions, each showcasing impressive performance relative to their size.
- Google has introduced three new experimental AI models: **Gemini 1.5 Flash8B**, **Gemini 1.5 Pro** Enhanced, and **Gemini 1.5 Flash** Updated.
- **Ideogram 2.0** has been released, offering image generation capabilities that surpass those of other leading models.
- Luma has unveiled the **Dream Machine 1.5** model for video creation.

## September
- The French AI company Mistral has introduced **Pixtral12B**, its first multimodal model capable of processing both images and text.
- OPENAI has released two nextgeneration AI models to its subscribers: **o1 preview** and **o1 mini**. These models show a significant improvement in performance, particularly in tasks requiring reasoning, including coding, mathematics, GPQA, and more. (*special*)
- Chinese company Alibaba releases the **Qwen 2.5** model in various sizes, ranging from 0.5B to 72B. The models demonstrate capabilities comparable to much larger models.
- The video generation model **KLING 1.5** has been released.
- **OpenAI** launches the **advanced voice mode** of GPT 4o for all subscribers.
- **Meta** releases **Llama 3.2** in sizes 1B, 3B, 11B and 90B, featuring image recognition capabilities for the first time.
- **Google** has rolled out new model updates ready for deployment, **Gemini Pro 1.5 002** and **Gemini Flash 1.5 002**, showcasing significantly improved longcontext processing.
- **Kyutai** releases two opensource versions of its voicetovoice model, **Moshi**.
- Google releases an update to its AI tool **NotebookLM** that enables users to create podcasts based on their own content.
- Mistral AI launches a 22B model named **Mistral Small**.

## October
- **Flux 1.1 Pro** is released, showcasing advanced capabilities for image creation.
- Meta unveils **Movie Gen**, a new AI model that generates videos, images, and audio from text input.
- Pika introduces **Video Model 1.5** along with "Pika Effects."
- Adobe announces its video creation model, **Firefly Video**.
- Startup Rhymes AI releases **Aria**, an opensource, multimodal model exhibiting capabilities similar to comparably sized proprietary models.
- Meta releases an opensource speechtospeech language model named **Meta Spirit LM**.
- Mistral AI introduces **Ministral**, a new model available in 3B and 8B parameter sizes.
- **Janus AI**, a multimodal language model capable of recognizing and generating both text and images, is released as open source by DeepSeekAI.
- Google DeepMind and MIT unveil **Fluid**, a texttoimage generation model with industryleading performance at a scale of 10.5B parameters.
- **Stable Diffusion 3.5** is released in three sizes as open source.
- Anthropic launches **Claude 3.5 Sonnet New**, demonstrating significant advancements in specific areas over its previous version, and announces **Claude 3.5 Haiku**.
- Anthropic announces an experimental feature for computer use with a public beta API.
- The texttoimage model **Recraft v3** has been released to the public, ranking first in benchmarks compared to similar models.
- OpenAI has launched **Search GPT**, allowing users to perform web searches directly within the platform.

## November
- Alibaba released its new model, **QwQ 32B Preview**, which integrates reasoning capabilities before responding. The model competes with, and sometimes surpasses, OpenAI's o1-preview model.
- Alibaba opensourced the model **Qwen2.5 Coder 32B**, which offers comparable capabilities to leading proprietary language models in the coding domain.
- DeepSeek unveiled its new AI model, **DeepSeek-R1-Lite-Preview**, which incorporates reasoning capabilities and delivers impressive performance on the AIME and MATH benchmarks, matching the level of OpenAI's o1-preview.
- **Suno** upgraded its AIpowered music generator to **v4**, introducing new features and performance improvements.
- Mistral AI launched the **Pixtral Large** model, a multimodal language model excelling in image recognition and advanced performance metrics, and an update to Mistral Large, 2411.
- Google introduced two experimental models, **gemini-exp-1114** and **gemini-exp-1121**, currently leading the arena chatbot with enhanced performance.
- Anthropic launches **Claude 3.5 Haiku** and Visual PDF Analysis in Claude.

## December
- Amazon introduced a new series of models called **NOVA**, designed for text, image, and video processing.
- OpenAI released **SORA**, a video generation model, along with the full version of **o1** and **o1 Pro** for advanced subscribers. Additionally, the company launched a live video mode for **GPT 4o**. (*special*)
- Google unveiled the experimental model **Gemini-Exp-1206**, which ranked first in the chatbot leaderboard.
- Google launched **Gemini 2.0 Flash** in beta. This model leads benchmarks and outperforms the previous version, **Gemini Pro 1.5**. Additionally, Google introduced live speech and video mode and announced built-in image generation capabilities within the model. (*special*)
- Google revealed **Gemini-2.0-Flash-Thinking**, a thinking model based on **Gemini 2.0 Flash**, which secured second place in the chatbot leaderboard. (*special*)
- Google introduced **Veo 2**, a beta version video generation model capable of producing 4K videos up to two minutes long. The model outperformed **SORA** in human evaluations. Additionally, Google updated **Imagen 3**, offering enhanced image quality and realism. (*special*)
- xAI integrated **Aurora**, a new model for generating high-quality and realistic images.
- Microsoft open-sourced the **Phi4** model, sized at 14B, showcasing impressive capabilities for its size.
- Meta released **Llama 3.3 70B**, a model offering performance comparable to **Llama 3.1 405B**.
- Google launched a multi-modal open-source model called **PaliGemma 2**, integrated with existing **Gemma** models.
- Pika Labs released **2.0**, the latest version of its AI-powered video generator.
- Meta introduced **Apollo**, a video generation model available in three different sizes.
- Deepseek open-sourced **Deepseek V3**, a model with 671B parameters that surpasses closed-source SOTA models across several benchmarks. (*special*)
- Alibaba unveiled **QVQ-72B-Preview**, a cutting-edge thinking model capable of analyzing images, featuring SOTA-level performance. (*special*)
- OpenAI announced **o3**, a groundbreaking AI model achieving 87.5% in the **ARC-AGI** benchmark, 25.2% in the **Frontier Math Benchmark** (compared to under 2% in previous models), and 87.7% in Ph.D.-level science questions. A cost-effective version, **o3 Mini**, is expected in January 2025, with performance similar to **o1**, alongside improved speed and efficiency. (*special*)
- The video generation model **Kling 1.6** was released, offering significant performance enhancements.


# Year: 2025

## January
- OpenAI released **Operator** for Pro subscribers – an experimental AI agent capable of browsing websites and performing actions. (*special*)
- Google introduced **Gemini Flash Thinking 0121**, an enhanced reasoning model that secured the top spot in the Arena Chatbots rankings.
- DeepSeek open-sourced the reasoning models **R1** and **R1-Zero**, which demonstrated capabilities similar to **o1** across various domains at a fraction of the cost. Additionally, smaller distilled models were released, achieving high performance relative to their size. (*special*)
- Google published a research paper on a new language model architecture called **Titans**, designed to enable models to retain both short- and long-term memory. This architecture significantly improves processing for extended context windows. (*special*)
- DeepSeek open-sourced a fully multimodal model, **Janus Pro 7B**, which supports both text and image generation.
- Alibaba unveiled **Qwen2.5-Max**, a large language model that surpasses several leading models, including **DeepSeek-V3**, **GPT-4o**, and **Claude 3.5**. Additionally, the **Qwen2.5-1M** series was open-sourced, capable of processing up to one million tokens, along with the **Qwen2.5-VL** vision model series in three different sizes.
- OpenAI made the **o3 mini** reasoning model available to all users, including the free tier, featuring three reasoning levels. The model matches or comes close to o1 in several benchmarks, significantly surpasses it in coding, and remains significantly faster and more cost-efficient. (*special*)

## February 2025
- xAI launches **Grok 3**, **Grok 3 Reasoning** and **Grok 3 mini**, next-generation AI models trained with 10 times the computing power of Grok 2, significantly improving SOTA performance. They include "Think" and "Big Brain" modes for advanced reasoning, as well as **DeepSearch** for autonomous web searches. (*special*)
- Anthropic introduces **Claude 3.7** and **Claude 3.7 Thinking**, a new model with enhanced coding performance, support for "Extended Thinking" mode, and the ability to analyze reasoning processes. (*special*)
- OpenAI unveils **Deep Research**, a tool for autonomous research, enabling real-time web searches and comprehensive report generation. (*special*)
- Google releases **Gemini 2.0 Flash**, **Gemini 2.0 Flash-Lite Preview**, and **Gemini 2.0 Pro Experimental**.
- Alibaba launches **QwQ-Max** – a reasoning model based on Qwen2.5-Max, offering improved analytical and logical capabilities.
- Microsoft presents **Phi4-mini** and **Phi4 Multimodal**, lightweight models (3.8B and 5.6B) with enhanced performance, including support for multimodal inputs.
- OpenAI releases **GPT-4.5**, featuring advanced pattern recognition and significantly reduced hallucinations, improving accuracy and reliability. (*special*)

## March 2025
- Google introduced **Gemini 2.5 Pro**, an experimental "Thinking model" with advanced reasoning and planning capabilities, a 1 million token context window, achieving top rankings across several key benchmarks. (*special*)
- Google launched the Gemma 3 series, featuring open-source multimodal models in various parameter sizes, a 128K context window, multi-language support, and integrated image and video understanding capabilities.
- OpenAI integrated **GPT-4o Image Generation**, enabling high-fidelity text-to-image creation, text rendering within images, and more. (*special*)
- Google expanded experimental image generation and editing within **Gemini 2.0 Flash Experimental**, enabling image generation and editing, including enhanced text creation capabilities. (*special*)
- Alibaba released **QwQ-32B**, an open-source 32B parameter reasoning model with exceptional math and coding performance, rivaling much larger models.
- Alibaba released the **Qwen2.5-VL 32B**, open-source vision-language model with robust capabilities in visual analysis, text-in-image understanding, and visual agent tasks.
- DeepSeek updated its open-source MoE model with **DeepSeek-V3-0324**, featuring enhanced reasoning, coding, and math capabilities, positioning it as a top-tier base model.
- Sesame AI unveiled its **Conversational Speech Model (CSM)**, enabling remarkably human-like, real-time voice interaction, incorporating emotional nuances, natural pauses, laughter, and contextual memory. (*special*)

## April 2025
- Meta releases **Llama 4** in three sizes with a context window of 10 million tokens and medium performance.
- Google launches **Gemini 2.5 Flash**, with a dynamic reasoning mode that allows tuning the reasoning level or disabling it as needed.
- Amazon introduces **Nova Act**, a new framework for building multi-step autonomous agents.
- OpenAI releases **GPT-4.1** in three sizes, with a context window of 1 million tokens.
- OpenAI introduces **o3 full** and **o4 mini**, highly advanced models for reasoning, math, and coding.
- Midjourney launches **v7**, with higher image quality and more precise control over style.
- A series of video model updates - **Veo 2.0** (Google), **Runway Gen-4**, **Vidu Q1**, and **Kling 2.0** – a leap forward in high-quality video generation, with improvements in response times, realism, and style.
- Alibaba releases **Qwen 3** as open source, in various sizes, with very impressive capabilities for their size. (*special*)

## May 2025
- Microsoft launches the **Phi-4 reasoning** series as open source, small yet high-quality models that incorporate reasoning.
- Suno releases **Suno 4.5**, fixing shimmer noise and improving audio decay stability in long tracks.
- Anthropic releases **Claude 4 Opus** and **Claude Sonnet 4**: Opus 4 offers a Hybrid "Deep Thought" mode with enhanced long-term context and 7-hour autonomous operation; Sonnet 4 focuses on improved math and coding performance. (*special*)
- Google releases **Veo 3**, a video generation model for synchronized 4K video with natural audio integration, and **Imagen 4**, an advanced image model with deeper contextual understanding and artistic style support. (*special*)
- OpenAI releases **Codex**, an autonomous code agent in ChatGPT, powered by the o3 model, for writing code, debugging, testing, and creating GitHub Pull Requests.
- Google releases **Jules**, an asynchronous autonomous coding agent on Gemini 2.5 Pro, analyzing repositories and creating GitHub Pull Requests.
- Google releases **Gemini 2.5 Pro** (Deep Think Mode) and **Gemini 2.5 Flash**, featuring improved reasoning, native audio support, extended context, and high-frequency task handling.
- OpenAI updates **Operator** to use the **o3** model, achieving SOTA on OSWorld benchmarks and enhancing autonomous browser capabilities.
- DeepSeek open-sources **R1-0528**, a code-and-inference model with near–o4-mini performance and moderate computational needs.
- Google DeepMind launches **AlphaEvolve**, an autonomous code-optimizer using evolutionary strategies with LLMs, achieving SOTA on 75% of math problems and discovering enhanced algorithms 20% of the time. (*special*)
- Google releases **Gemini Diffusion**, an experimental text diffusion model achieving high-speed text generation with enhanced control and creativity via noise refinement. (*special*)
- Google introduces **Gemma 3n**, an open-source generative AI model for on-device use, with an efficient architecture and multi-modal (audio, text, visual) capabilities.


## June 2025
- Google releases **Gemini 2.5 Pro** (final production-ready version), which leads benchmarks across the board.
- ElevenLabs rolls out **Eleven v3 (alpha)** TTS with fine grained emotion control and support for 70+ languages.
- OpenAI debuts **o3 pro**, an enhanced reasoning model offering extended context and real-time tool integrations.

## July 2025
- xAI releases **Grok 4**, achieving a new SOTA of 15.9% on ARC-AGI v2 and 25.4% on Humanity’s Last Exam. (*special*)
- OpenAI unveils the **ChatGPT Agent**, embedding autonomous coding, web research and tool use directly within the chat interface. (*special*)
- An experimental OpenAI model secures a **gold medal** at IMO 2025 without any external tools. (*special*)
- Google introduces **Gemini Deep Think**, which also earns an IMO 2025 gold by solving five of six problems with parallel reasoning. (*special*)
- Alibaba open-sources two variants, **Qwen3-235B-A22B-Instruct-2507** (instruction-tuned) and **Qwen3-Coder**, for general LLM use and automated code generation.
- Moonshot AI debuts **Kimi K2**, a Chinese LLM praised for its open-research focus and robust performance.
- Chinese startup Zhipu open-sources **GLM-4.5**, a 130 B-parameter model tailored for intelligent-agent applications.

## August 2025
- Google introduced **Gemini 2.5 Deep Think**, a special "extended thinking" mode for solving complex problems and exploring alternatives. (*special*)
- Anthropic released **Claude Opus 4.1**, an upgrade focused on improving agentic capabilities and real-world coding.
- Google DeepMind announced **Genie 3.0**, a "world model" for creating interactive 3D environments from text, maintaining consistency for several minutes. (*special*)
- OpenAI released **gpt-oss-120b** and **gpt-oss-20b**, a family of open-source models with high reasoning capabilities, optimized to run on accessible hardware.
- OpenAI launched **GPT-5**, the company's next-generation model, with significant improvements in coding and a dynamic "thinking" mode to reduce hallucinations.
- DeepSeek released **DeepSeek V3.1**, a hybrid model combining fast and slow "thinking" modes to improve performance in agentic tasks and tool use.
- Google launched a preview of **Gemini 2.5 Flash Image** (showcased as *nano-banana*), an advanced model for precise image editing, merging, and maintaining character consistency. (*special*)


## September 2025

-   ByteDance released **Seedream 4.0**, a next-generation image model unifying high-quality text-to-image generation and natural-language image editing.
-   An advanced Gemini variant, reported as **Gemini 2.5 - Deep Think**, achieved gold-medal-level performance at the ICPC World Finals programming contest. (*special*)
-   OpenAI reported a reasoning and code model achieved a perfect score (12/12) in ICPC testing. (*special*)
-   Suno released **Suno v5**, an upgrade in music generation with studio-grade fidelity and more natural-sounding vocals.
-   Alibaba unveiled **Qwen-3-Max**, its flagship model with over a trillion parameters, focusing on long context and agent capabilities.
-   **Wan 2.5** was released, a generative video model focused on multi-shot consistency and character animation.
-   Anthropic announced **Claude Sonnet 4.5**, a model optimized for coding, agent construction, and improved reasoning.
-   OpenAI released **Sora 2**, a flagship video and audio generation model with improved physical modeling and synchronized sound.
-   DeepSeek released **DeepSeek-V3.2-Exp**
-   OpenAI and NVIDIA announced a strategic partnership for NVIDIA to supply at least **10 gigawatts** of AI systems for OpenAI's infrastructure. (*special*)

## October 2025

-   Figure unveiled **Figure 03**, a humanoid robot designed for domestic and general-purpose tasks.
-   Google released a **Gemini model for computer control**, achieving state-of-the-art (SOTA) performance in GUI automation.
-   Anthropic released **Claude 4.5 Haiku**, a fast, cost-effective model for high-volume, low-latency applications.
-   OpenAI announced **ChatGPT Atlas**, an AI-native web browser with a built-in "Agent Mode" for task automation.
-   1X announced **Neo**, a humanoid robot marketed as the first consumer-ready model for home use. (*special*)


## November 2025

-   Moonshot AI released **Kimi K2 Thinking**, an open model setting new records in reasoning benchmarks.
-   OpenAI launched **GPT 5.1**, featuring specialized "Thinking" and "Instant" modes with expanded context.
-   xAI released **Grok 4.1**, combining high EQ with strong logic to top the LM Arena leaderboard.
-   Google debuted **Gemini 3.0**, a flagship "thinking" model that claimed the top spot on major benchmarks.
-   OpenAI introduced **GPT 5.1 Codex Max**, an agentic model built specifically for long-term coding tasks.
-   Google released **Nano Banana Pro**, a superior image generation and editing model based on Gemini 3. (*special*)
-   Anthropic announced **Claude Opus 4.5**, delivering elite coding and agentic performance at a significantly reduced price. (*special*)
-   Black Forest Labs launched **FLUX 2**, a high-performance open-weight image generation model.
-   DeepSeek released **DeepSeekMath-V2** as open source, achieving gold-medal performance in math olympiads. (*special*)
-   Microsoft open-sourced **Fara-7B**, a small model optimized for browser agents and computer control.
-   **Poetiq** shatters the **ARC-AGI-2** benchmark with a score of over 60%, surpassing the human average.


## December 2025
- Mistral AI launches the **Mistral 3** family (Large & Ministral) alongside **Mistral OCR 3** and the **Devstral 2** coding series, reinforcing its open-weight leadership with advanced agentic workflows and Vibe CLI integration.
- OpenAI releases **GPT-5.2**, featuring the autonomous **Codex** agent for complex engineering tasks, and **GPT-Image 1.5**, which claims the #1 spot on vision benchmarks, outperforming Nano Banana Pro.
- Google introduces **Gemini 3.0 Flash**, setting a new standard for price-performance, and deploys **Deep Research**, an autonomous agent capable of multi-step synthesis, alongside **Gemini 2.5 Flash Audio**. (*special*)
- Amazon unveils the **Nova 2** series, highlighted by **Nova 2 Sonic**, a native speech-to-speech model delivering ultra-low latency and natural conversation flow.
- Runway releases **Gen-4.5**, a video generation model that rises to the top of industry leaderboards for motion consistency and prompt adherence.
- xAI launches the **Grok Voice Agent API**, enabling native, real-time bidirectional audio streaming for developers.
- Zhipu AI releases **GLM-4.7**, an open-weights model that reaches the top of global coding and reasoning leaderboards.
- Alibaba open-sources **Z-Image-Turbo**, a highly efficient 6B model, and releases **Qwen-Image-2512**, which specializes in high-fidelity typography and complex visual compositions.
- MiniMax releases **MiniMax-M2.1**, a 200k-context MoE model that rises to the top of web development and coding leaderboards, establishing itself as a leading open model for developers.
- A specialized system by **Poetiq**, powered by GPT-5.2, reportedly solves the **ARC-2** benchmark, marking a major breakthrough in abstract reasoning. (*special*)
