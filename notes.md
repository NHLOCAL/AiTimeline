---
layout: default
published: false
---

### שכתוב בעברית:

- OpenAI שחררה למנויי פרו את **Operator** - סוכן AI נסיוני המסוגל לגלוש באתרים ולבצע פעולות
- Google שחררה את Gemini Flash thinking 0121, מודל חשיבה משופר. המודל הגיע למקום הראשון ב-Arena chatbots
- Deepseek שחררה כקוד פתוח מודלי חשיבה בשם R1 ו-R1-Zero, שהציג יכולות דומות למודל o1 במגוון תחומים ושבריר מהמחיר. בנוסף שחררה החברה מודלים מזוקקים קטנים יותר שהציגו ביצועים גבוהים מאוד ביחס לגודלם
- Google הציגה נייר מחקר של ארכיקטורה חדשה לבניית מודלי שפה בשם **Titans** המאפשרת למודלים לשמור זיכרון לטווח קצר וארוך. הארכיקטורה משפרת משמעותית עיבוד של חלון הקשר מוגדל
- Deepseek שחררה כקוד פתוח מודל רב מודאלי מלא בשם **Janus Pro 7B** הכולל יצירת תמונות וטקסט כאחד.
- עליבאבא חשפה את **Qwen2.5-Max**, מודל שפה גדול שמנצח מספר דגמים מובילים כמו Deepseek-V3 , GPT-4o , ו-Claude 3.5. בנוסף שחררה החברה כקוד פתוח סדר מודלים בשם **Qwen2.5-1M** המסוגלים לנתח עד מיליון אסימונים ואת סדרת דגמי ראייה **Qwen2.5-VL** בשלושה גדלים.


### שכתוב באנגלית

- OpenAI released **Operator** for Pro subscribers – an experimental AI agent capable of browsing websites and performing actions.  
- Google introduced **Gemini Flash Thinking 0121**, an enhanced reasoning model that secured the top spot in the Arena Chatbots rankings.  
- DeepSeek open-sourced the reasoning models **R1** and **R1-Zero**, which demonstrated capabilities similar to **o1** across various domains at a fraction of the cost. Additionally, smaller distilled models were released, achieving high performance relative to their size.  
- Google published a research paper on a new language model architecture called **Titans**, designed to enable models to retain both short- and long-term memory. This architecture significantly improves processing for extended context windows.  
- DeepSeek open-sourced a fully multimodal model, **Janus Pro 7B**, which supports both text and image generation.  
- Alibaba unveiled **Qwen2.5-Max**, a large language model that surpasses several leading models, including **DeepSeek-V3**, **GPT-4o**, and **Claude 3.5**. Additionally, the **Qwen2.5-1M** series was open-sourced, capable of processing up to one million tokens, along with the **Qwen2.5-VL** vision model series in three different sizes.